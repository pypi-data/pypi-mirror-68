//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-26218862
// Cuda compilation tools, release 10.1, V10.1.168
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_30
.address_size 64

	// .globl	__miss__radiance
.const .align 8 .b8 params[264];

.visible .entry __miss__radiance(

)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<16>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<5>;


	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd2, %r1;
	shl.b64 	%rd3, %rd2, 32;
	cvt.u64.u32	%rd4, %r2;
	or.b64  	%rd1, %rd3, %rd4;
	ld.u32 	%r3, [%rd1+12];
	ld.const.v2.u32 	{%r4, %r5}, [params+224];
	or.b32  	%r8, %r3, -2147483648;
	ld.const.u32 	%r9, [params+220];
	st.v4.u32 	[%rd1], {%r9, %r4, %r5, %r8};
	and.b32  	%r10, %r3, 16777216;
	setp.eq.s32	%p1, %r10, 0;
	@%p1 bra 	BB0_2;

	ld.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd1+16];
	ld.const.f32 	%f8, [params+220];
	ld.const.v2.f32 	{%f9, %f10}, [params+224];
	mul.ftz.f32 	%f12, %f9, %f2;
	mul.ftz.f32 	%f13, %f8, %f1;
	st.v2.f32 	[%rd1+16], {%f13, %f12};
	mul.ftz.f32 	%f15, %f10, %f3;
	st.f32 	[%rd1+24], %f15;

BB0_2:
	ret;
}

	// .globl	__miss__radiance_ambient
.visible .entry __miss__radiance_ambient(

)
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<28>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<5>;


	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd2, %r1;
	shl.b64 	%rd3, %rd2, 32;
	cvt.u64.u32	%rd4, %r2;
	or.b64  	%rd1, %rd3, %rd4;
	ld.u32 	%r3, [%rd1+44];
	setp.eq.s32	%p1, %r3, 0;
	@%p1 bra 	BB1_2;

	ld.const.v2.f32 	{%f1, %f2}, [params+232];
	ld.const.f32 	%f5, [params+240];
	st.v2.f32 	[%rd1], {%f1, %f2};
	st.f32 	[%rd1+8], %f5;
	bra.uni 	BB1_3;

BB1_2:
	ld.const.v2.f32 	{%f6, %f7}, [params+224];
	ld.const.f32 	%f10, [params+220];
	st.v2.f32 	[%rd1], {%f10, %f6};
	st.f32 	[%rd1+8], %f7;

BB1_3:
	ld.u32 	%r4, [%rd1+12];
	or.b32  	%r5, %r4, -2147483648;
	st.u32 	[%rd1+12], %r5;
	and.b32  	%r6, %r4, 16777216;
	setp.eq.s32	%p2, %r6, 0;
	@%p2 bra 	BB1_5;

	ld.v4.f32 	{%f11, %f12, %f13, %f14}, [%rd1+16];
	ld.v4.f32 	{%f18, %f19, %f20, %f21}, [%rd1];
	mul.ftz.f32 	%f23, %f19, %f12;
	mul.ftz.f32 	%f25, %f18, %f11;
	st.v2.f32 	[%rd1+16], {%f25, %f23};
	mul.ftz.f32 	%f27, %f20, %f13;
	st.f32 	[%rd1+24], %f27;

BB1_5:
	ret;
}

	// .globl	__miss__radiance_ambient_and_vol
.visible .entry __miss__radiance_ambient_and_vol(

)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<85>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<7>;


	// inline asm
	call (%r5), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r6), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd4, %r5;
	shl.b64 	%rd5, %rd4, 32;
	cvt.u64.u32	%rd6, %r6;
	or.b64  	%rd1, %rd5, %rd6;
	add.s64 	%rd2, %rd1, 12;
	ld.u32 	%r1, [%rd1+12];
	and.b32  	%r7, %r1, 4096;
	setp.eq.s32	%p1, %r7, 0;
	@%p1 bra 	BB2_4;

	add.s64 	%rd3, %rd1, 28;
	ld.u32 	%r8, [%rd1+28];
	mad.lo.s32 	%r9, %r8, 1664525, 1013904223;
	and.b32  	%r10, %r9, 16777215;
	cvt.rn.f32.u32	%f11, %r10;
	mov.f32 	%f12, 0f4B800000;
	div.approx.ftz.f32 	%f13, %f11, %f12;
	mad.lo.s32 	%r11, %r9, 1664525, 1013904223;
	ld.f32 	%f14, [%rd1+92];
	st.u32 	[%rd1+28], %r11;
	and.b32  	%r12, %r11, 16777215;
	cvt.rn.f32.u32	%f15, %r12;
	div.approx.ftz.f32 	%f1, %f15, %f12;
	ld.v4.f32 	{%f16, %f17, %f18, %f19}, [%rd1+128];
	fma.rn.ftz.f32 	%f20, %f13, 0f40000000, %f14;
	add.ftz.f32 	%f21, %f20, 0fBF800000;
	add.ftz.f32 	%f22, %f14, %f14;
	mul.ftz.f32 	%f23, %f13, %f22;
	sub.ftz.f32 	%f24, %f23, %f14;
	add.ftz.f32 	%f25, %f24, 0f3F800000;
	div.approx.ftz.f32 	%f6, %f21, %f25;
	st.f32 	[%rd1+136], %f6;
	mul.ftz.f32 	%f26, %f6, %f6;
	mov.f32 	%f27, 0f3F800000;
	sub.ftz.f32 	%f7, %f27, %f26;
	mov.f32 	%f84, 0f00000000;
	setp.leu.ftz.f32	%p2, %f7, 0f00000000;
	@%p2 bra 	BB2_3;

	sqrt.approx.ftz.f32 	%f84, %f7;

BB2_3:
	add.ftz.f32 	%f28, %f1, %f1;
	mul.ftz.f32 	%f29, %f28, 0f40490FDB;
	cos.approx.ftz.f32 	%f30, %f29;
	mul.ftz.f32 	%f31, %f84, %f30;
	sin.approx.ftz.f32 	%f32, %f29;
	mul.ftz.f32 	%f33, %f84, %f32;
	mov.b32 	 %r13, %f18;
	and.b32  	%r14, %r13, -2147483648;
	or.b32  	%r15, %r14, 1065353216;
	mov.b32 	 %f34, %r15;
	mul.ftz.f32 	%f35, %f34, %f6;
	add.ftz.f32 	%f36, %f18, %f34;
	mul.ftz.f32 	%f37, %f17, %f33;
	fma.rn.ftz.f32 	%f38, %f16, %f31, %f37;
	fma.rn.ftz.f32 	%f39, %f36, %f35, %f38;
	abs.ftz.f32 	%f40, %f18;
	add.ftz.f32 	%f41, %f40, 0f3F800000;
	div.approx.ftz.f32 	%f42, %f39, %f41;
	mul.ftz.f32 	%f43, %f16, %f42;
	mul.ftz.f32 	%f44, %f17, %f42;
	mul.ftz.f32 	%f45, %f36, %f42;
	sub.ftz.f32 	%f46, %f45, %f35;
	sub.ftz.f32 	%f47, %f44, %f33;
	sub.ftz.f32 	%f48, %f43, %f31;
	st.v2.f32 	[%rd3+100], {%f48, %f47};
	st.f32 	[%rd1+136], %f46;
	ld.v4.f32 	{%f49, %f50, %f51, %f52}, [%rd1+80];
	or.b32  	%r21, %r1, 512;
	mov.b32 	 %r16, %f51;
	mov.b32 	 %r17, %f50;
	mov.b32 	 %r18, %f49;
	st.v4.u32 	[%rd1], {%r18, %r17, %r16, %r21};
	st.v4.f32 	[%rd1+48], {%f27, %f27, %f27, %f27};
	bra.uni 	BB2_8;

BB2_4:
	ld.u32 	%r19, [%rd1+44];
	setp.eq.s32	%p3, %r19, 0;
	@%p3 bra 	BB2_6;

	ld.const.v2.f32 	{%f57, %f58}, [params+232];
	ld.const.f32 	%f61, [params+240];
	st.v2.f32 	[%rd1], {%f57, %f58};
	st.f32 	[%rd1+8], %f61;
	bra.uni 	BB2_7;

BB2_6:
	ld.const.v2.f32 	{%f62, %f63}, [params+224];
	ld.const.f32 	%f66, [params+220];
	st.v2.f32 	[%rd1], {%f66, %f62};
	st.f32 	[%rd1+8], %f63;

BB2_7:
	or.b32  	%r21, %r1, -2147483648;
	st.u32 	[%rd2], %r21;

BB2_8:
	and.b32  	%r20, %r21, 16777216;
	setp.eq.s32	%p4, %r20, 0;
	@%p4 bra 	BB2_10;

	ld.v4.f32 	{%f67, %f68, %f69, %f70}, [%rd1+16];
	ld.v4.f32 	{%f74, %f75, %f76, %f77}, [%rd1];
	mul.ftz.f32 	%f79, %f75, %f68;
	mul.ftz.f32 	%f81, %f74, %f67;
	st.v2.f32 	[%rd1+16], {%f81, %f79};
	mul.ftz.f32 	%f83, %f76, %f69;
	st.f32 	[%rd1+24], %f83;

BB2_10:
	ret;
}

	// .globl	__miss__radiance_texturecart
.visible .entry __miss__radiance_texturecart(

)
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<33>;
	.reg .b32 	%r<21>;
	.reg .b64 	%rd<11>;


	// inline asm
	call (%r4), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r5), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd3, %r4;
	shl.b64 	%rd4, %rd3, 32;
	cvt.u64.u32	%rd5, %r5;
	or.b64  	%rd1, %rd4, %rd5;
	add.s64 	%rd2, %rd1, 12;
	ld.u32 	%r6, [%rd1+12];
	or.b32  	%r20, %r6, -2147483648;
	ld.u32 	%r7, [%rd1+44];
	st.u32 	[%rd1+12], %r20;
	setp.eq.s32	%p1, %r7, 0;
	@%p1 bra 	BB3_2;

	ld.const.v2.f32 	{%f1, %f2}, [params+232];
	ld.const.f32 	%f5, [params+240];
	st.v2.f32 	[%rd1], {%f1, %f2};
	st.f32 	[%rd1+8], %f5;
	bra.uni 	BB3_3;

BB3_2:
	// inline asm
	call (%r8), _optix_get_launch_index_x, ();
	// inline asm
	ld.const.u64 	%rd6, [params+16];
	cvta.to.global.u64 	%rd7, %rd6;
	mul.wide.u32 	%rd8, %r8, 8;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.v2.u32 	{%r11, %r12}, [%rd9];
	cvt.rn.f32.s32	%f6, %r11;
	cvt.rn.f32.s32	%f7, %r12;
	ld.const.v2.u32 	{%r15, %r16}, [params+64];
	cvt.rn.f32.u32	%f8, %r15;
	cvt.rn.f32.u32	%f9, %r16;
	div.approx.ftz.f32 	%f10, %f6, %f8;
	div.approx.ftz.f32 	%f11, %f7, %f9;
	ld.const.u64 	%rd10, [params+248];
	tex.2d.v4.f32.f32	{%f12, %f13, %f14, %f15}, [%rd10, {%f10, %f11}];
	st.v2.f32 	[%rd1], {%f12, %f13};
	st.f32 	[%rd1+8], %f14;
	ld.u32 	%r20, [%rd2];

BB3_3:
	and.b32  	%r19, %r20, 16777216;
	setp.eq.s32	%p2, %r19, 0;
	@%p2 bra 	BB3_5;

	ld.v4.f32 	{%f16, %f17, %f18, %f19}, [%rd1+16];
	ld.v4.f32 	{%f23, %f24, %f25, %f26}, [%rd1];
	mul.ftz.f32 	%f28, %f24, %f17;
	mul.ftz.f32 	%f30, %f23, %f16;
	st.v2.f32 	[%rd1+16], {%f30, %f28};
	mul.ftz.f32 	%f32, %f25, %f18;
	st.f32 	[%rd1+24], %f32;

BB3_5:
	ret;
}

	// .globl	__miss__radiance_envtexture
.visible .entry __miss__radiance_envtexture(

)
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<81>;
	.reg .b32 	%r<21>;
	.reg .b64 	%rd<7>;


	// inline asm
	call (%r3), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r4), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd3, %r3;
	shl.b64 	%rd4, %rd3, 32;
	cvt.u64.u32	%rd5, %r4;
	or.b64  	%rd1, %rd4, %rd5;
	add.s64 	%rd2, %rd1, 12;
	ld.u32 	%r5, [%rd1+12];
	or.b32  	%r6, %r5, -2147483648;
	ld.v4.f32 	{%f10, %f11, %f12, %f13}, [%rd1+128];
	st.u32 	[%rd1+12], %r6;
	abs.ftz.f32 	%f1, %f10;
	abs.ftz.f32 	%f2, %f12;
	setp.eq.ftz.f32	%p1, %f1, 0f00000000;
	setp.eq.ftz.f32	%p2, %f2, 0f00000000;
	and.pred  	%p3, %p1, %p2;
	mov.b32 	 %r1, %f10;
	mov.b32 	 %r7, %f12;
	and.b32  	%r2, %r7, -2147483648;
	@%p3 bra 	BB4_4;
	bra.uni 	BB4_1;

BB4_4:
	shr.s32 	%r14, %r1, 31;
	and.b32  	%r15, %r14, 1078530011;
	or.b32  	%r16, %r15, %r2;
	mov.b32 	 %f80, %r16;
	bra.uni 	BB4_5;

BB4_1:
	setp.eq.ftz.f32	%p4, %f1, 0f7F800000;
	setp.eq.ftz.f32	%p5, %f2, 0f7F800000;
	and.pred  	%p6, %p4, %p5;
	@%p6 bra 	BB4_3;
	bra.uni 	BB4_2;

BB4_3:
	shr.s32 	%r10, %r1, 31;
	and.b32  	%r11, %r10, 13483017;
	add.s32 	%r12, %r11, 1061752795;
	or.b32  	%r13, %r12, %r2;
	mov.b32 	 %f80, %r13;
	bra.uni 	BB4_5;

BB4_2:
	max.ftz.f32 	%f16, %f2, %f1;
	min.ftz.f32 	%f17, %f2, %f1;
	div.full.ftz.f32 	%f18, %f17, %f16;
	mul.rn.ftz.f32 	%f19, %f18, %f18;
	mov.f32 	%f20, 0fC0B59883;
	mov.f32 	%f21, 0fBF52C7EA;
	fma.rn.ftz.f32 	%f22, %f19, %f21, %f20;
	mov.f32 	%f23, 0fC0D21907;
	fma.rn.ftz.f32 	%f24, %f22, %f19, %f23;
	mul.ftz.f32 	%f25, %f19, %f24;
	mul.ftz.f32 	%f26, %f18, %f25;
	add.ftz.f32 	%f27, %f19, 0f41355DC0;
	mov.f32 	%f28, 0f41E6BD60;
	fma.rn.ftz.f32 	%f29, %f27, %f19, %f28;
	mov.f32 	%f30, 0f419D92C8;
	fma.rn.ftz.f32 	%f31, %f29, %f19, %f30;
	rcp.approx.ftz.f32 	%f32, %f31;
	fma.rn.ftz.f32 	%f33, %f26, %f32, %f18;
	mov.f32 	%f34, 0f3FC90FDB;
	sub.ftz.f32 	%f35, %f34, %f33;
	setp.gt.ftz.f32	%p7, %f2, %f1;
	selp.f32	%f36, %f35, %f33, %p7;
	mov.f32 	%f37, 0f40490FDB;
	sub.ftz.f32 	%f38, %f37, %f36;
	setp.lt.s32	%p8, %r1, 0;
	selp.f32	%f39, %f38, %f36, %p8;
	mov.b32 	 %r8, %f39;
	or.b32  	%r9, %r8, %r2;
	mov.b32 	 %f40, %r9;
	add.ftz.f32 	%f41, %f1, %f2;
	setp.gtu.ftz.f32	%p9, %f41, 0f7F800000;
	selp.f32	%f80, %f41, %f40, %p9;

BB4_5:
	fma.rn.ftz.f32 	%f42, %f80, 0f3E22F983, 0f3F000000;
	ld.f32 	%f43, [%rd1+132];
	abs.ftz.f32 	%f44, %f43;
	mov.f32 	%f45, 0f3F800000;
	sub.ftz.f32 	%f46, %f45, %f44;
	mul.ftz.f32 	%f47, %f46, 0f3F000000;
	sqrt.approx.ftz.f32 	%f48, %f47;
	setp.gt.ftz.f32	%p10, %f44, 0f3F11EB85;
	selp.f32	%f49, %f48, %f44, %p10;
	mul.ftz.f32 	%f50, %f49, %f49;
	mov.f32 	%f51, 0f3C94D2E9;
	mov.f32 	%f52, 0f3D53F941;
	fma.rn.ftz.f32 	%f53, %f52, %f50, %f51;
	mov.f32 	%f54, 0f3D3F841F;
	fma.rn.ftz.f32 	%f55, %f53, %f50, %f54;
	mov.f32 	%f56, 0f3D994929;
	fma.rn.ftz.f32 	%f57, %f55, %f50, %f56;
	mov.f32 	%f58, 0f3E2AAB94;
	fma.rn.ftz.f32 	%f59, %f57, %f50, %f58;
	mul.ftz.f32 	%f60, %f50, %f59;
	fma.rn.ftz.f32 	%f61, %f60, %f49, %f49;
	mov.f32 	%f62, 0f3FC90FDB;
	mov.f32 	%f63, 0fC0000000;
	fma.rn.ftz.f32 	%f64, %f63, %f61, %f62;
	selp.f32	%f65, %f64, %f61, %p10;
	setp.gtu.ftz.f32	%p11, %f65, 0f7F800000;
	mov.b32 	 %r17, %f65;
	mov.b32 	 %r18, %f43;
	and.b32  	%r19, %r18, -2147483648;
	or.b32  	%r20, %r17, %r19;
	mov.b32 	 %f66, %r20;
	selp.f32	%f67, %f65, %f66, %p11;
	fma.rn.ftz.f32 	%f68, %f67, 0fBEA2F983, 0f3F000000;
	ld.const.u64 	%rd6, [params+248];
	tex.2d.v4.f32.f32	{%f8, %f9, %f7, %f69}, [%rd6, {%f42, %f68}];
	st.v2.f32 	[%rd1], {%f8, %f9};
	st.f32 	[%rd1+8], %f7;
	ld.u8 	%rs1, [%rd2+3];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16	%p12, %rs2, 1;
	@!%p12 bra 	BB4_7;
	bra.uni 	BB4_6;

BB4_6:
	ld.v4.f32 	{%f70, %f71, %f72, %f73}, [%rd1+16];
	mul.ftz.f32 	%f77, %f9, %f71;
	mul.ftz.f32 	%f78, %f8, %f70;
	st.v2.f32 	[%rd1+16], {%f78, %f77};
	mul.ftz.f32 	%f79, %f7, %f72;
	st.f32 	[%rd1+24], %f79;

BB4_7:
	ret;
}


