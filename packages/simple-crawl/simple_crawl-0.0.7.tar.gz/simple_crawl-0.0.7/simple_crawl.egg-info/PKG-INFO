Metadata-Version: 2.1
Name: simple-crawl
Version: 0.0.7
Summary: Only need one line to crawl
Home-page: https://github.com/Amiee-well/crawl
Author: Lux
Author-email: 1223411083@qq.com
License: UNKNOWN
Project-URL: Blog, https://blog.csdn.net/qq_45414559/article/details/106005684
Description: ï»¿## ä»…éœ€ä¸€è¡Œä»£ç å†™çˆ¬è™«--simple_crawl
        
        ---
        
        ### simple_crawl
        - ä»…éœ€ä¸€è¡Œä»£ç å³å¯è¾¾åˆ°çˆ¬è™«æ•ˆæœ
        - é¡¹ç›®åœ°å€(æ¬¢è¿star):[https://github.com/Amiee-well/crawl](https://github.com/Amiee-well/crawl)
        
        ### ä½¿ç”¨æ–¹æ³•
        **pip install simple_crawl**
        
        ```python
        from simple_crawl import request
        request.parse(
            url='https://www.douban.com/group/explore',
            type_url='text',
            #login='taobao',
            Parsing = 'xpath',
            label = {
                'url':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/@href',str],
                'name':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/text()',str],
                'Author':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/div[2]/span[1]/a/text()',str]
                },
            write='result.csv',
            next_url='//*[@id="content"]/div/div[1]/div[2]/span[4]/a/@href',
            page=[True,'url_page.txt'],
            #clean=True,
            write_SQL={
                'host':'localhost',
                'post':'3306',
                'user':'root',
                'password':'123456',
                'db':'example',
                'table':'example'
                }
            ).run()
        ```
        ---
        ä»‹ç»ä¸€ä¸‹crawlå‚æ•°è®¾ç½®ï¼š
        
        ```python
        '''
        çˆ¬è™«ç¨‹åºæ‰§è¡Œ
        :param url:å³å°†è¯·æ±‚çš„urlåœ°å€,ä»…æ”¯æŒgetè¯·æ±‚
        :param type_url:è¯·æ±‚urlåè¿”å›æ ¼å¼,æ”¯æŒtextå’Œjsonæ ¼å¼è¿”å›
        :param login:æ¨¡æ‹Ÿç½‘ç«™ç™»é™†,ä¿å­˜ç™»é™†ä¿¡æ¯
        :param Parsing:çˆ¬è™«æ–¹å¼,æ”¯æŒreã€xpathä»¥åŠbs4æ–¹æ³•
        :param label:é€‰æ‹©å™¨å†…å®¹,å­—å…¸æ ¼å¼ä¿å­˜,
                     å­—å…¸å€¼ä¸ºåˆ—è¡¨æ ¼å¼,ç¬¬ä¸€ä¸ªå‚æ•°ä¸ºé€‰æ‹©å™¨,ç¬¬äºŒä¸ªå‚æ•°ä¸ºè½¬æ¢ç±»å‹
                     ç¬¬ä¸€ä¸ªå‚æ•°å¿…å¡«,ç¬¬äºŒä¸ªå‚æ•°é»˜è®¤strç±»å‹
        :param write:æ˜¯å¦å†™å…¥æ–‡ä»¶,æ”¯æŒtxtæ ¼å¼ã€csvæ ¼å¼ã€jsonæ ¼å¼ä»¥åŠpklæ ¼å¼,é»˜è®¤å¦,
        :param next_url:æ˜¯å¦è·¨é¡µçˆ¬è™«,é€‰æ‹©å™¨å†…å®¹ä½¿çˆ¬è™«ç»§ç»­ç¿»é¡µçˆ¬è™«
        :param page:æ˜¯å¦é€‰æ‹©æ–­ç»­ç¬”è®°æ¥æ‰‹ä¸‹æ¬¡çˆ¬è™«å¤„ç†,é»˜è®¤å¦
         :param clean:æ˜¯å¦è¿›è¡Œç®€å•ç±»å‹æ•°æ®æ¸…æ´—,é»˜è®¤å¦
        :param write_sql:æ˜¯å¦å†™å…¥æ•°æ®åº“,é»˜è®¤å¦
                         'host'é»˜è®¤ä¸º'localhost','post'é»˜è®¤'3306','user'é»˜è®¤'root',
                         'password':'å¯†ç ','db':'æ•°æ®åº“','table':'æ•°æ®è¡¨',
                         æ£€æµ‹è¡¨æ˜¯å¦å­˜åœ¨,è‹¥ä¸å­˜åœ¨åˆ™åˆ›å»º,è‹¥å­˜åœ¨åˆ™ç›´æ¥æ’å…¥.
        :return True
        '''
        ```
        ---
        ## ä»‹ç»ç©æ³•
        æ¥ä¸‹æ¥ä»‹ç»çš„å‡ä¸ºè°ƒç”¨ç¬¬ä¸‰æ–¹åº“çš„æƒ…å†µä¸‹è¿è¡Œï¼š
        
        ```python
        from simple_crawl import request
        ```
        
        ---
        ### ç¬¬ä¸€ç§ç©æ³•ï¼šè¾“å‡ºæºä»£ç 
        è°ƒç”¨requestsåº“è¿›è¡Œæºä»£ç è¯·æ±‚ã€‚
        
        ç‰¹ç‚¹ï¼š
        	è¯·æ±‚å¤±è´¥åˆ™è°ƒç”¨ipæ± å¤„ç†é‡æ–°è¯·æ±‚è®¿é—®ï¼Œ
        	å‡ºç°äº”æ¬¡å¤±è´¥é»˜è®¤ç½‘å€è¾“å…¥é”™è¯¯ã€‚
        	æ”¯æŒtextä»¥åŠjsonå­—ç¬¦ä¸²è¿”å›ã€‚é»˜è®¤textã€‚
        
        ç¼ºç‚¹ï¼š
        	æš‚æ—¶åªèƒ½è¿›è¡Œgetè¯·æ±‚ï¼Œä¸æ”¯æŒpostè®¿é—®
        
        ï¼šreturn text or json
        ```python
        request.parse(
        	url = "https://www.douban.com/group/explore",
        	type_url = "text"
        ).run()
        # return text
        ```
        ---
        ### ç¬¬äºŒç§ç©æ³•ï¼šæ¨¡æ‹Ÿç½‘ç«™ç™»é™†å¹¶ä¿å­˜ä¿¡æ¯
        è°ƒç”¨DecryptLoginåº“è¯·æ±‚ç™»é™†è®¿é—®ã€‚
        
        > psï¼šDecryptLoginåº“ä¸ºå¤§ä½¬çš®å¡ä¸˜å†™çš„ä¸€ä¸ªå¾ˆä¸é”™çš„æ¨¡æ‹Ÿç½‘ç«™ç™»é™†åº“ï¼Œåœ¨æ­¤å¼•ç”¨ä¸€ä¸‹ï¼Œå› ä¸ºå•è¡Œçˆ¬è™«åŸå› ä¸æ”¯æŒè´¦å·å¯†ç ç™»é™†ï¼Œæˆ‘å°†å¤§ä½¬å†™çš„äºŒç»´ç ç™»é™†ä½¿ç”¨è¿‡æ¥äº†ã€‚å†æ¬¡æ„Ÿè°¢å¤§ä½¬å¼€æº
        > åœ¨æ­¤æ”¾å‡ºæ–‡æ¡£åœ°å€
        > DecryptLoginåº“ä¸­æ–‡æ–‡æ¡£ï¼š[https://httpsgithubcomcharlespikachudecryptlogin.readthedocs.io/zh/latest/](https://httpsgithubcomcharlespikachudecryptlogin.readthedocs.io/zh/latest/)
        > 
        
        ç‰¹ç‚¹ï¼š
        	å°†DecryptLoginåº“ä¸­äºŒç»´ç ç»§æ‰¿åˆ°æ­¤åº“ï¼ˆéäºŒæ¬¡å¼€å‘ï¼‰
        	æ”¯æŒQQç¾¤ã€QQç©ºé—´ã€QQå®‰å…¨ä¸­å¿ƒã€æ·˜å®ã€äº¬ä¸œå’Œæ–—é±¼ç™»é™†ï¼ˆå¤§ä½¬ç™»é™†åº“ä¸­æ‰€æœ‰çš„äºŒç»´ç ç™»é™†ï¼‰
        	ä¿å­˜session.pklä¿¡æ¯åˆ°æœ¬åœ°æ–¹ä¾¿ä¸‹æ¬¡ç™»é™†è¿è¡Œ
        
        ç¼ºç‚¹ï¼š
        	session.pklç™»é™†ä¿¡æ¯è¿‡æ—¶æ— æ³•è‡ªåŠ¨åˆ é™¤ã€‚
        	å¯¼è‡´ä¸‹æ¬¡ç™»é™†ç–‘ä¼¼cookieæ— æ³•æ­£å¸¸ç™»é™†ã€‚
        
        :return session
        
        ```python
        request.parse(
        	# è‡­ä¸è¦è„¸çš„æ¨å¹¿ä¸€ä¸‹æˆ‘çš„åº—é“º
        	url="https://shop574805287.taobao.com/",
        	login="taobao"
        ).run()
        # return text
        ```
        ---
        ### ç¬¬ä¸‰ç§ç©æ³•ï¼šçˆ¬å–ç½‘ç«™ä¿¡æ¯
        çˆ¬è™«åº“è‡ªç„¶å°‘ä¸äº†çˆ¬è™«çš„è¿‡ç¨‹
        
        ç‰¹ç‚¹ï¼š
        	æ”¯æŒreåº“ï¼Œxpathè§£æä»¥åŠbs4é€‰æ‹©å™¨ã€‚
        	çˆ¬å–æ–¹æ³•ä¸ºå­—å…¸æ ¼å¼ã€‚å•æ–¹é¢è¾“å‡ºã€‚
        	å­—å…¸é”®ä¸ºä¿å­˜çš„å­—æ®µåç§°ã€‚
        	å­—å…¸å€¼ä¸ºåˆ—è¡¨æ ¼å¼ï¼šç¬¬ä¸€ä¸ªå‚æ•°ä¸ºé€‰æ‹©å™¨ï¼Œç¬¬äºŒä¸ªå‚æ•°ä¸ºè½¬æ¢ç±»å‹ã€‚ç¬¬ä¸€ä¸ªå‚æ•°å¿…å¡«ï¼Œç¬¬äºŒä¸ªå‚æ•°é»˜è®¤	strç±»å‹ã€‚
        
        ç¼ºç‚¹ï¼šæš‚æ— ï¼ˆç­‰å¾…å°ä¼™ä¼´ä»¬å‘ç°ï¼‰
        
        ï¼šreturn reptile_results
        ```python
        request.parse(
        	url='https://www.douban.com/group/explore',
        	# å­—ç¬¦ä¸²æ ¼å¼,é€‰æ‹©å™¨æ–¹æ³•ã€‚
            Parsing = 'xpath',
            # å­—å…¸æ ¼å¼,å‚æ•°å¦‚ä¸Šã€‚
            label = {
                'url':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/@href',str],
                'name':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/text()',str],
                'Author':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/div[2]/span[1]/a/text()',str]
                }
        ).run()
        # return reptile_resultsï¼ˆlistï¼‰
        ```
        ---
        ### ç¬¬å››ç§ç©æ³•ï¼šè‡ªç”±ä¿å­˜ä¿¡æ¯
        ç›®å‰ç‰ˆæœ¬æ”¯æŒä¿å­˜txtã€csvã€jsonä»¥åŠpklå››å¤§ä¸»æµæ–‡ä»¶ã€‚æ—¥åç‰ˆæœ¬æ›´æ–°å°†å‘å¸ƒæ›´ä¸ºå…¨é¢çš„ä¿å­˜æ–¹æ³•ã€‚
        
        ç‰¹ç‚¹ï¼š
        	å†™å…¥æ–‡ä»¶å‡ä¸ºæ•°æ®æ ¼å¼ä¼ å…¥æ–‡ä»¶ã€‚
        	ä¸”è¾“å…¥æ ¼å¼è§„èŒƒæ–¹ä¾¿é˜…è¯»andçœäº‹ã€‚
        
        ç¼ºç‚¹ï¼š
        	ä¿å­˜æ ¼å¼ä»…å››ç§ï¼Œ
        	ä¸æ–¹ä¾¿ç”¨æˆ·ä¹‹åè¯»å†™æ“ä½œã€‚
        
        ï¼šreturn file
        
        ```python
        request.parse(
        	url='https://www.douban.com/group/explore',
            Parsing = 'xpath',
            label = {
                'url':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/@href',str],
                'name':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/text()',str],
                'Author':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/div[2]/span[1]/a/text()',str]
                },
            # å­—ç¬¦ä¸²æ ¼å¼,å…·ä½“ä¿å­˜ä½ç½®å¡«å†™
            write='result.pkl'
        ).run()
        # return file
        ```
        ---
        ### ç¬¬äº”ç§ç©æ³•ï¼šè¯»å–ä¸‹ä¸€é¡µ url åœ°å€ç»§ç»­çˆ¬è™«
        è¿™ä¹Ÿæ˜¯æ¯ä¸ªäººéƒ½æ‹…å¿ƒçš„é—®é¢˜ï¼Œä»…ä»…ä¸€è¡Œä»£ç æ€ä¹ˆå¯èƒ½ç¿»é¡µçˆ¬è™«ã€‚è¿™è¿˜çœŸèƒ½åšåˆ°å“¦~
        
        ç‰¹ç‚¹ï¼š
        	ç»§æ‰¿ä¹‹å‰çš„Parsingå‚æ•°é€‰æ‹©å™¨é€‰æ‹©æ–¹æ³•ã€‚
        	åœ¨è¿™é‡Œå¯è¯»å–åˆ°è§£æåçš„ä¸‹ä¸€é¡µ url ç½‘å€ã€‚
        	æ–¹å¯ç»§ç»­è¿›è¡Œçˆ¬è™«å¤„ç†ã€‚æ–¹ä¾¿ç”¨æˆ·ä½¿ç”¨ã€‚
        
        ç¼ºç‚¹ï¼š
        	è‹¥çˆ¬è™«æ—¶ä¸‹ä¸€é¡µ url åœ°å€æ”¹å˜ï¼Œä¾¿ç»“æŸçˆ¬è™«ã€‚
        	åªèƒ½çˆ¬å–æ‰€ç»™ url åœ°å€ä¸­çš„ä¿¡æ¯ã€‚
        	æ— æ³•è¿›è¡ŒæŸä¸€ç•Œé¢çš„å¤šä¸ªç½‘é¡µçˆ¬å–è¿”å›ã€‚
        	é€ æˆè®¿é—®é¡µé¢å•ä¸€æµå¤±ã€‚
        
        ï¼šreturn None
        
        ```python
        request.parse(
        	url='https://www.douban.com/group/explore',
            Parsing = 'xpath',
            label = {
                'url':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/@href',str],
                'name':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/text()',str],
                'Author':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/div[2]/span[1]/a/text()',str]
                },
            write='result.pkl',
            # å­—ç¬¦ä¸²æ ¼å¼,æ ¹æ®Parsingæ–¹æ³•ç»§ç»­è¯·æ±‚ä¸‹ä¸€é¡µaä¸­href
            next_url='//*[@id="content"]/div/div[1]/div[2]/span[4]/a/@href',
        ).run()
        # return None 
        ```
        ---
        ### ç¬¬å…­ç§ç©æ³•ï¼šçˆ¬è™«ç½‘é¡µä¿å­˜
        å¬è¯´è¿‡çˆ¬è™«æ–­ç»­é‡è¿çš„æœ‹å‹åº”è¯¥æ‡‚å¾—è¿™æ˜¯ä¸ªä»€ä¹ˆç¥ä»™æ“ä½œã€‚æ¯æ¬¡çˆ¬è™«è¿è¡ŒæœŸé—´å¥½å¥½çš„ï¼Œç¡ä¸€è§‰é†’æ¥å‘ç°ä»£ç æŠ¥é”™äº†ã€‚ã€‚ã€‚è¿™å°±æ˜¯ä¸ªå¾ˆéš¾å—çš„äº‹ï¼Œè¿˜ä¸çŸ¥é“ä¹‹å‰çˆ¬å–åˆ°å“ªä¸€é¡µäº†ï¼Œåªèƒ½é‡æ–°çˆ¬è™«äº†å•Šï¼
        
        ç‰¹ç‚¹ï¼š
        	æŒç»­è¾“å‡ºæ–­ç»­ç¬”è®°ã€‚
        	å°†æ­¤æ¬¡çˆ¬è™«çš„ url åœ°å€ä¿å­˜åˆ°ä¸€ä¸ªæ–‡æœ¬æ–‡æ¡£å†…éƒ¨ã€‚
        	ä¸‹æ¬¡è¯»å–æ–‡æœ¬æ–‡æ¡£å³å¯å¿«é€Ÿè¿›è¡Œç›´æ¥æ–­æ‰çš„çˆ¬è™« url åœ°å€ç»§ç»­çˆ¬å–æ‰€éœ€ã€‚
        
        ç¼ºç‚¹ï¼š
        	è¯»å–å†…å®¹ä¸å•ä¸€ã€‚
        	å¯¼è‡´ä¸‹æ¬¡çˆ¬è™«æ— æ³•æ­£ç¡®è¯»å–ä¸Šæ¬¡çˆ¬è™«ç•™ä¸‹çš„ç—•è¿¹ã€‚
        
        ï¼šreturn url_file
        
        ```python
        request.parse(
            url='https://www.douban.com/group/explore',
            type_url='text',
            Parsing = 'xpath',
            label = {
                'url':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/@href',str],
                'name':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/text()',str],
                'Author':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/div[2]/span[1]/a/text()',str]
                },
            write='result.pkl',
            next_url='//*[@id="content"]/div/div[1]/div[2]/span[4]/a/@href',
            # ç¬¬ä¸€ä¸ªå‚æ•°ä¸ºæ˜¯å¦éœ€è¦æ–­ç»­ç¬”è®°ã€‚
            # ç¬¬äºŒä¸ªå‚æ•°ä¸ºæ–­ç»­ç¬”è®°ä¿å­˜ä½ç½®ã€‚
            page=[True,'url_page.txt']
        ).run()
        # return url_file
        ```
        ### ç¬¬ä¸ƒç§ç©æ³•ï¼šç®€å•æ•°æ®æ¸…æ´—
        æ•°æ®æ‹¿ä¸‹åï¼Œç›´æ¥ä¿å­˜åˆ°æœ¬åœ°æœ‰äº›å¤§ä½¬å¯èƒ½è§‰å¾—å¾ˆè¾£é¸¡ï¼Œè¿æ¸…æ´—éƒ½ä¸æ¸…æ´—å°±å­˜å…¥æœ¬åœ°äº†ï¼Ÿé‚£å¾—æ‹¿åˆ°å¤šå°‘åºŸæ•°æ®è„æ•°æ®ã€‚é‚£ä¹ˆæ¥ä¸‹æ¥ä»‹ç»ä¸€ä¸‹æ¸…æ´—å‚æ•°ã€‚
        
        ç‰¹ç‚¹ï¼š
        	æœ¬äººæ›¾å†™è¿‡ä¸€ä¸ªåº•å±‚æ•°æ®æ¸…æ´—ã€‚
        	èƒ½å°†åˆ—è¡¨æ ¼å¼æ•°æ®è¿›è¡Œå½’åˆ†æ¸…æ´—ã€‚
        	ä¸»è¦å†…å®¹è¯·å‚è€ƒå¦ä¸€ç¯‡æ–‡ç« 
        	å¦‚ä¸‹è¿æ¥ï¼š[æ•°æ®æ¸…æ´—](https://blog.csdn.net/qq_45414559/article/details/105907938)
        
        ç¼ºç‚¹ï¼š
        	æ•°æ®æ¸…æ´—æ ¼å¼ç®€å•ã€‚
        	æ•°æ®æ¸…æ´—å†…å®¹å•ä¸€ã€‚
        	æ— æ³•å®Œå…¨åšåˆ°ç»å¯¹æ¸…æ´—ã€‚
        	æœ‰å¾…æ”¹å–„ã€‚
        
        ï¼šreturn keyword_list, value_list
        
        ```python
        request.parse(
            url='https://www.douban.com/group/explore',
            Parsing = 'xpath',
            label = {
                'url':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/@href',str],
                'name':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/text()',str],
                'Author':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/div[2]/span[1]/a/text()',str]
                },
            write='result.pkl',
            next_url='//*[@id="content"]/div/div[1]/div[2]/span[4]/a/@href',
            page=[True,'url_page.txt'],
            # boolç±»å‹,é»˜è®¤ä¸æ¸…æ´—
            clean=True
        ).run()
        ```
        ---
        ### ç¬¬å…«ç§ç©æ³•ï¼šçˆ¬è™«å­˜å…¥æ•°æ®åº“
        å­˜åˆ°txtã€å­˜åˆ°csvã€å­˜åˆ°jsonã€å­˜åˆ°pklï¼Œé‚£ä¹Ÿå¤ªlowäº†å§ã€‚ç°åœ¨æµè¡Œçš„æ•°æ®åº“ç”¨ä¸äº†ä¹ˆï¼Ÿé‚£æ˜¯ä¸å¯èƒ½çš„ã€‚ã€‚
        
        ç‰¹ç‚¹ï¼š
        	ä¿¡æ¯å­˜å…¥MySQLæ•°æ®åº“ã€‚
        	å¯è¿æ¥dockerè¿œç¨‹æ•°æ®åº“ã€‚
        	æ•°æ®åº“çš„åº“åå¿…é¡»å­˜åœ¨ã€‚
        	æ•°æ®åº“çš„è¡¨åå¯ä»¥ä¸å­˜åœ¨ã€‚
        	æ ¹æ®ä¹‹å‰ä¼ å…¥å­—å…¸é”®ä¸å€¼å‚æ•°åˆ¤æ–­è¡¨ç±»å‹ã€‚
        	è‡ªç”±å»ºç«‹æ•°æ®è¡¨ä¼ å…¥ä¿¡æ¯ã€‚
        
        ç¼ºç‚¹ï¼š
        	ä»…æ”¯æŒMySQLæ•°æ®åº“ã€‚
        	ä¸èƒ½è‡ªç”±åˆ›å»ºæ•°æ®åº“ã€‚
        
        ï¼šreturn SQL
        
        ```python
        request.parse(
            url='https://www.douban.com/group/explore',
            Parsing = 'xpath',
            label = {
                'url':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/@href',str],
                'name':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/h3/a/text()',str],
                'Author':['//*[@id="content"]/div/div[1]/div[1]/div[1]/div[2]/div[2]/span[1]/a/text()',str]
                },
            write='result.pkl',
            next_url='//*[@id="content"]/div/div[1]/div[2]/span[4]/a/@href',
            page=[True,'url_page.txt'],
            clean=True,
            # å­—å…¸æ ¼å¼,
            # hostå¯æœ‰å¯æ— ,é»˜è®¤localhost
            # postå¯æœ‰å¯æ— ,é»˜è®¤3306
            # userå¯æœ‰å¯æ— ,é»˜è®¤root
            # passwordå¿…è¦å‚æ•°,æ•°æ®åº“è¿æ¥å¯†ç 
            # dbå¿…è¦å‚æ•°,æ•°æ®åº“å³å°†å­˜å…¥çš„åº“å
            # tableå¿…è¦å‚æ•°,æ•°æ®åº“å³å°†å­˜å…¥çš„è¡¨å
            write_SQL={
                'host':'localhost',
                'post':'3306',
                'user':'root',
                'password':'123456',
                'db':'example',
                'table':'example'
                }
            ).run()
        ```
        ---
        ### åŠŸèƒ½ä»‹ç»å®Œæ¯•ğŸ¤
        
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Description-Content-Type: text/markdown
