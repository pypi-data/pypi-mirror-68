{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-14 13:19:39,084 INFO : Run until first stop...\n",
      "2020-01-14 13:19:39,970 INFO : Epoch 0\n",
      "2020-01-14 13:19:39,971 INFO : train_loss                3.42033\n",
      "2020-01-14 13:19:39,971 INFO : valid_loss                2.83930\n",
      "2020-01-14 13:19:39,972 INFO : train_misclass            0.47500\n",
      "2020-01-14 13:19:39,973 INFO : valid_misclass            0.46667\n",
      "2020-01-14 13:19:39,973 INFO : runtime                   0.00000\n",
      "2020-01-14 13:19:39,974 INFO : \n",
      "2020-01-14 13:19:41,138 INFO : Time only for training updates: 1.16s\n",
      "2020-01-14 13:19:42,007 INFO : Epoch 1\n",
      "2020-01-14 13:19:42,009 INFO : train_loss                0.80030\n",
      "2020-01-14 13:19:42,009 INFO : valid_loss                1.41156\n",
      "2020-01-14 13:19:42,010 INFO : train_misclass            0.40000\n",
      "2020-01-14 13:19:42,010 INFO : valid_misclass            0.50000\n",
      "2020-01-14 13:19:42,011 INFO : runtime                   2.05409\n",
      "2020-01-14 13:19:42,011 INFO : \n",
      "2020-01-14 13:19:43,128 INFO : Time only for training updates: 1.12s\n",
      "2020-01-14 13:19:43,939 INFO : Epoch 2\n",
      "2020-01-14 13:19:43,940 INFO : train_loss                0.36340\n",
      "2020-01-14 13:19:43,941 INFO : valid_loss                0.98899\n",
      "2020-01-14 13:19:43,941 INFO : train_misclass            0.15000\n",
      "2020-01-14 13:19:43,942 INFO : valid_misclass            0.36667\n",
      "2020-01-14 13:19:43,942 INFO : runtime                   1.99085\n",
      "2020-01-14 13:19:43,943 INFO : \n",
      "2020-01-14 13:19:45,016 INFO : Time only for training updates: 1.07s\n",
      "2020-01-14 13:19:45,882 INFO : Epoch 3\n",
      "2020-01-14 13:19:45,883 INFO : train_loss                0.25743\n",
      "2020-01-14 13:19:45,883 INFO : valid_loss                0.82574\n",
      "2020-01-14 13:19:45,884 INFO : train_misclass            0.12500\n",
      "2020-01-14 13:19:45,885 INFO : valid_misclass            0.36667\n",
      "2020-01-14 13:19:45,885 INFO : runtime                   1.88649\n",
      "2020-01-14 13:19:45,885 INFO : \n",
      "2020-01-14 13:19:47,000 INFO : Time only for training updates: 1.11s\n",
      "2020-01-14 13:19:47,833 INFO : Epoch 4\n",
      "2020-01-14 13:19:47,834 INFO : train_loss                0.18925\n",
      "2020-01-14 13:19:47,835 INFO : valid_loss                0.68131\n",
      "2020-01-14 13:19:47,835 INFO : train_misclass            0.10000\n",
      "2020-01-14 13:19:47,836 INFO : valid_misclass            0.33333\n",
      "2020-01-14 13:19:47,836 INFO : runtime                   1.98543\n",
      "2020-01-14 13:19:47,837 INFO : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_misclass</th>\n",
       "      <th>valid_misclass</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.420333</td>\n",
       "      <td>2.839304</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.800297</td>\n",
       "      <td>1.411565</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.054093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.363404</td>\n",
       "      <td>0.988987</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.990847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.257427</td>\n",
       "      <td>0.825735</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.886488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.189247</td>\n",
       "      <td>0.681307</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.985432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  valid_loss  train_misclass  valid_misclass   runtime\n",
       "0    3.420333    2.839304           0.475        0.466667  0.000000\n",
       "1    0.800297    1.411565           0.400        0.500000  2.054093\n",
       "2    0.363404    0.988987           0.150        0.366667  1.990847\n",
       "3    0.257427    0.825735           0.125        0.366667  1.886488\n",
       "4    0.189247    0.681307           0.100        0.333333  1.985432"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Trialwise Decoding\n",
    "==================\n",
    "\n",
    "In this example, we will use a convolutional neural network on the\n",
    "[Physiobank EEG Motor Movement/Imagery Dataset](https://www.physionet.org/physiobank/database/eegmmidb/) to decode two classes:\n",
    "\n",
    "1. Executed and imagined opening and closing of both hands\n",
    "2. Executed and imagined opening and closing of both feet\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "We use only one subject (with 90 trials) in this tutorial for demonstration\n",
    "purposes. A more interesting decoding task with many more trials would be\n",
    "to do cross-subject decoding on the same dataset.\n",
    "\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Enable logging\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)  # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Load data\n",
    "# ---------\n",
    "\n",
    "# You can load and preprocess your EEG dataset in any way,\n",
    "# Braindecode only expects a 3darray (trials, channels, timesteps) of input\n",
    "# signals `X` and a vector of labels `y` later (see below). In this tutorial,\n",
    "# we will use the [MNE](https://www.martinos.org/mne/stable/index.html)\n",
    "# library to load an EEG motor imagery/motor execution dataset. For a\n",
    "# tutorial from MNE using Common Spatial Patterns to decode this data, see\n",
    "# [here](http://martinos.org/mne/stable/auto_examples/decoding/plot_decoding_csp_eeg.html).\n",
    "# For another library useful for loading EEG data, take a look at\n",
    "# [Neo IO](https://pythonhosted.org/neo/io.html).\n",
    "\n",
    "import mne\n",
    "from mne.io import concatenate_raws\n",
    "\n",
    "# 5,6,7,10,13,14 are codes for executed and imagined hands/feet\n",
    "subject_id = 22  # carefully cherry-picked to give nice results on such limited data :)\n",
    "event_codes = [5, 6, 9, 10, 13, 14]\n",
    "# event_codes = [3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "# This will download the files if you don't have them yet,\n",
    "# and then return the paths to the files.\n",
    "physionet_paths = mne.datasets.eegbci.load_data(subject_id, event_codes)\n",
    "\n",
    "# Load each of the files\n",
    "parts = [mne.io.read_raw_edf(path, preload=True, stim_channel='auto',\n",
    "                             verbose='WARNING')\n",
    "         for path in physionet_paths]\n",
    "\n",
    "# Concatenate them\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "# Find the events in this dataset\n",
    "events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "# Use only EEG channels\n",
    "eeg_channel_inds = \\\n",
    "    mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "# Extract trials, only using EEG channels\n",
    "epoched = mne.Epochs(raw, events, dict(hands_or_left=2, feet_or_right=3),\n",
    "                     tmin=1, tmax=4.1, proj=False, picks=eeg_channel_inds,\n",
    "                     baseline=None, preload=True)\n",
    "\n",
    "##############################################################################\n",
    "# Convert data to Braindecode format\n",
    "# ----------------------------------\n",
    "\n",
    "# Braindecode has a minimalistic ```SignalAndTarget``` class, with\n",
    "# attributes `X` for the signal and `y` for the labels. `X` should have\n",
    "# these dimensions: trials x channels x timesteps. `y` should have one\n",
    "# label per trial.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert data from volt to millivolt\n",
    "# Pytorch expects float32 for input and int64 for labels.\n",
    "X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "y = (epoched.events[:, 2] - 2).astype(np.int64)  # 2,3 -> 0,1\n",
    "\n",
    "\n",
    "# We use the first 40 trials for training and the next 30 trials for\n",
    "# validation. The validation accuracies can be used to tune hyperparameters\n",
    "# such as learning rate etc. The final 20 trials are split apart so we have\n",
    "# a final hold-out evaluation set that is not part of any hyperparameter\n",
    "# optimization. As mentioned before, this dataset is dangerously small to\n",
    "# get any meaningful results and only used here for quick demonstration\n",
    "# purposes.\n",
    "\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "\n",
    "train_set = SignalAndTarget(X[:40], y=y[:40])\n",
    "valid_set = SignalAndTarget(X[40:70], y=y[40:70])\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Create the model\n",
    "# ----------------\n",
    "\n",
    "# Braindecode comes with some predefined convolutional neural network\n",
    "# architectures for raw time-domain EEG. Here, we use the shallow ConvNet\n",
    "# model from [Deep learning with convolutional neural networks for EEG\n",
    "# decoding and visualization](https://arxiv.org/abs/1703.05051).\n",
    "\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "from braindecode.torch_ext.util import set_random_seeds  # XXX : move to braindecode.util\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=train_set.X.shape[2],\n",
    "                        final_conv_length='auto')\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "# We use [AdamW](https://arxiv.org/abs/1711.05101) to optimize the parameters of our network together with [Cosine Annealing](https://arxiv.org/abs/1608.03983) of the learning rate. We supply some default parameters that we have found to work well for motor decoding, however we strongly encourage you to perform your own hyperparameter optimization using cross validation on your training data.\n",
    "\n",
    "# <div class=\"alert alert-info\">\n",
    "#\n",
    "# We will now use the Braindecode model class directly to perform the training in a few lines of code. If you instead want to use your own training loop, have a look at the [Trialwise Low-Level Tutorial](./TrialWise_LowLevel.html).\n",
    "#\n",
    "# </div>\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# from braindecode.torch_ext.optimizers import AdamW\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "# optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = Adam(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)\n",
    "\n",
    "# ## Run the training\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "n_epochs = 4\n",
    "model.fit(train_set.X, train_set.y, n_epochs=n_epochs, batch_size=64,\n",
    "          scheduler='cosine', validation_data=(valid_set.X, valid_set.y))\n",
    "\n",
    "\n",
    "# The monitored values are also stored into a pandas dataframe:\n",
    "\n",
    "model.epochs_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
