"""
Text Labeling Model https://kashgari.bmio.net/tutorial/text-labeling/#performance-report
BERT with TF 2.0 https://github.com/google-research/bert/issues/485
基于注意力的神经机器翻译 https://www.tensorflow.org/tutorials/text/nmt_with_attention
How to add an attention mechanism in keras? https://stackoverflow.com/questions/42918446/how-to-add-an-attention-mechanism-in-keras
https://www.tensorflow.org/tutorials/text/nmt_with_attention
https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#self-attention
https://colab.research.google.com/drive/1RvCnR7h0_l4Ekn5vINWToI9TNJdpUZB3#scrollTo=dVeQNDaHtveP
https://github.com/philipperemy/keras-attention-mechanism
https://github.com/uzaymacar/attention-mechanisms
https://github.com/hanxiao/bert-as-service
https://github.com/AdroitAnandAI/LSTM-Attention-based-Generative-Chat-bot
https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077
https://github.com/CyberZHG/keras-bert
https://github.com/brightmart/albert_zh
https://medium.com/huggingface/introducing-fastbert-a-simple-deep-learning-library-for-bert-models-89ff763ad384
Attention机制详解（二）——Self-Attention与Transformer https://zhuanlan.zhihu.com/p/47282410
"""